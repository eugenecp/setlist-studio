# Setlist Studio CI/CD Pipeline
# Comprehensive build, test, and security workflow for the Setlist Studio application
# Includes automated testing, security scanning, code quality checks, and deployment preparation
name: CI/CD Pipeline

# Workflow Triggers
# - Push to main: Full CI/CD pipeline with deployment steps
# - Pull Request to main: Build, test, and security validation
# - Manual dispatch: On-demand pipeline execution for troubleshooting
on:
  push:
    branches: [ main ]                # Production deployments
  pull_request:
    branches: [ main ]                # Pre-merge validation
  workflow_dispatch:                  # Manual triggering for troubleshooting

# Security Permissions
# Minimal required permissions following principle of least privilege
permissions:
  contents: read                      # Read repository contents
  checks: write                       # Write test results and status checks
  pull-requests: write               # Comment on pull requests with reports
  actions: read                       # Read workflow and action information

# Environment Variables
# Global configuration for .NET and optimization settings
env:
  DOTNET_VERSION: '8.0.x'            # Target .NET version for consistency
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: 1 # Skip .NET welcome and telemetry setup
  DOTNET_NOLOGO: true                 # Suppress .NET logo in build output
  DOTNET_CLI_TELEMETRY_OPTOUT: 1     # Disable .NET CLI telemetry for privacy

jobs:
  # JOB 1: Build, Test, and Quality Assurance
  # Comprehensive build pipeline with testing, security scanning, and quality checks
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    steps:
    # Step 1: Checkout source code with full Git history
    # Full history needed for security analysis and change detection
    - name: 🔄 Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0                # Fetch complete Git history for analysis tools
    
    # Step 2: Setup .NET development environment
    # Installs specified .NET version for consistent builds across environments
    - name: 🏗️ Setup .NET
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: ${{ env.DOTNET_VERSION }}
    
    # Step 3: Cache NuGet packages for faster builds
    # Reduces build time by caching dependencies between workflow runs
    - name: 📦 Cache NuGet packages
      uses: actions/cache@v4
      with:
        path: ~/.nuget/packages        # NuGet global packages folder
        key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj') }} # Cache key based on project files
        restore-keys: |               # Fallback cache keys for partial matches
          ${{ runner.os }}-nuget-
    
    # Step 4: Display .NET environment information for troubleshooting
    # Helps diagnose environment-specific build issues
    - name: 🔍 Display .NET info
      run: dotnet --info
    
    # Step 5: Restore NuGet package dependencies
    # Downloads all required packages before building
    - name: 📥 Restore dependencies
      run: dotnet restore SetlistStudio.sln
    
    # Step 6: Build the solution in Release configuration
    # Compiles all projects with optimizations enabled
    - name: 🏗️ Build solution
      run: dotnet build SetlistStudio.sln --configuration Release --no-restore --verbosity normal
    
    # Step 7: Execute comprehensive test suite with clean environment
    # Runs all unit tests with proper cleanup to avoid conflicts
    - name: 🧪 Run tests with clean environment
      run: |
        # Kill any potential background dotnet processes to avoid file locking
        pkill -f "dotnet.*SetlistStudio" || true
        sleep 2
        
        # Clean any previous builds to ensure fresh test environment
        dotnet clean SetlistStudio.sln --configuration Release
        
        # Set test environment variables to avoid database conflicts
        export ASPNETCORE_ENVIRONMENT=Testing
        export DOTNET_ENVIRONMENT=Testing
        export CI=true

        # Run comprehensive test suite with coverage collection
        dotnet test SetlistStudio.sln --configuration Release --verbosity normal --logger trx --logger "console;verbosity=detailed" --collect "XPlat Code Coverage" --results-directory ./test-results
    
    # Step 8: Upload test results and coverage data as artifacts
    # Preserves test results for analysis and reporting
    - name: 📊 Upload test results
      uses: actions/upload-artifact@v4
      if: always() # Upload even if tests fail
      with:
        name: test-results
        path: |
          ./test-results/*.trx
          ./test-results/**/*.xml
        retention-days: 30
    
    # Step 9: Upload code coverage data for analysis
    # Provides coverage metrics for quality monitoring
    - name: 📈 Upload code coverage
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: code-coverage
        path: ./test-results/**/coverage.cobertura.xml
        retention-days: 30
    
    # Step 10: Parse and display test results summary
    # Creates human-readable test results in GitHub workflow summary
    - name: 📋 Parse test results
      if: always()                       # Run even if previous steps failed
      run: |
        echo "## 🧪 Test Results" >> $GITHUB_STEP_SUMMARY
        
        # Find and process TRX files for test result summary
        if find ./test-results -name "*.trx" -type f | head -1 | grep -q .; then
          echo "Test results found, processing..." >> $GITHUB_STEP_SUMMARY
          
          # Parse TRX files to extract test statistics
          for trx_file in ./test-results/*.trx; do
            if [ -f "$trx_file" ]; then
              echo "Processing: $trx_file" >> $GITHUB_STEP_SUMMARY
              
              # Extract test statistics using XML parsing with more robust approach
              if grep -q "outcome" "$trx_file"; then
                # Count test outcomes more precisely and clean up the results
                passed=$(grep -o 'outcome="Passed"' "$trx_file" 2>/dev/null | wc -l | tr -d ' \n' || echo "0")
                failed=$(grep -o 'outcome="Failed"' "$trx_file" 2>/dev/null | wc -l | tr -d ' \n' || echo "0")
                skipped=$(grep -o 'outcome="NotExecuted"' "$trx_file" 2>/dev/null | wc -l | tr -d ' \n' || echo "0")
                
                # Clean any whitespace and ensure we have valid numbers
                passed=$(echo "$passed" | tr -d ' \n' | grep -E '^[0-9]+$' || echo "0")
                failed=$(echo "$failed" | tr -d ' \n' | grep -E '^[0-9]+$' || echo "0")
                skipped=$(echo "$skipped" | tr -d ' \n' | grep -E '^[0-9]+$' || echo "0")
                
                # Validate that all variables are numbers
                if [[ "$passed" =~ ^[0-9]+$ ]] && [[ "$failed" =~ ^[0-9]+$ ]] && [[ "$skipped" =~ ^[0-9]+$ ]]; then
                  total=$((passed + failed + skipped))
                  
                  echo "- ✅ Passed: $passed" >> $GITHUB_STEP_SUMMARY
                  echo "- ❌ Failed: $failed" >> $GITHUB_STEP_SUMMARY
                  echo "- ⏭️ Skipped: $skipped" >> $GITHUB_STEP_SUMMARY  
                  echo "- 📊 Total: $total" >> $GITHUB_STEP_SUMMARY
                  
                  # Fail the workflow if any tests failed
                  if [ "$failed" -gt 0 ]; then
                    echo "- 🚨 Status: FAILED" >> $GITHUB_STEP_SUMMARY
                    exit 1
                  else
                    echo "- ✅ Status: PASSED" >> $GITHUB_STEP_SUMMARY
                  fi
                else
                  echo "- ⚠️ Invalid test counts after cleanup: passed='$passed', failed='$failed', skipped='$skipped'" >> $GITHUB_STEP_SUMMARY
                fi
              else
                echo "- ⚠️ Could not find test outcomes in $trx_file" >> $GITHUB_STEP_SUMMARY
              fi
            fi
          done
        else
          echo "⚠️ No test result files found in ./test-results/" >> $GITHUB_STEP_SUMMARY
          ls -la ./test-results/ >> $GITHUB_STEP_SUMMARY || echo "test-results directory not found" >> $GITHUB_STEP_SUMMARY
        fi
    
    # Step 11: Publish formatted test results (alternative method)
    # Uses specialized action for better test result visualization
    - name: 📋 Publish test results (Alternative)
      uses: dorny/test-reporter@v1.9.1
      if: always() && github.event_name != 'pull_request' # Skip on PRs to avoid permission issues
      with:
        name: Test Results               # Display name for test report
        path: './test-results/*.trx'     # Path to TRX test result files (directly in test-results)
        reporter: dotnet-trx             # Use .NET TRX format reporter
        fail-on-error: false             # Don't fail workflow on test failures (handled elsewhere)
        token: ${{ secrets.GITHUB_TOKEN }} # GitHub token for API access
    
    # Step 12: Generate code coverage summary report
    # Creates formatted coverage report for quality monitoring
    - name: 🎯 Code Coverage Summary
      uses: irongut/CodeCoverageSummary@v1.3.0
      if: always()                         # Run even if tests failed
      with:
        filename: './test-results/**/coverage.cobertura.xml' # Cobertura coverage file
        badge: true                      # Generate coverage badge
        fail_below_min: true             # Fail workflow when coverage drops below 80%
        format: markdown                 # Output format for GitHub display
        hide_branch_rate: false          # Show branch coverage metrics
        hide_complexity: false           # Show code complexity metrics
        indicators: true                 # Show visual indicators for coverage levels
        output: both                     # Output to console and file
        thresholds: '80 90'              # Fail below 80%, excellent at 90% coverage
    
    # Step 13: Create comprehensive test and build summary for pull requests
    # Provides detailed feedback on PR quality and test results
    - name: 📝 Create test summary for PR
      if: github.event_name == 'pull_request' # Only run on pull requests
      run: |
        echo "## 🧪 Test & Build Summary" > pr-summary.md
        echo "" >> pr-summary.md
        
        # Add build status information
        echo "### 🏗️ Build Status" >> pr-summary.md
        echo "- ✅ Build completed successfully" >> pr-summary.md
        echo "- 📦 NuGet packages restored" >> pr-summary.md
        echo "- 🐳 Docker image built and tested" >> pr-summary.md
        echo "" >> pr-summary.md
        
        # Add test results
        echo "### 🧪 Test Results" >> pr-summary.md
        if find ./test-results -name "*.trx" -type f | head -1 | grep -q .; then
          echo "- ✅ All tests executed" >> pr-summary.md
          echo "- 📊 Test artifacts generated" >> pr-summary.md
          echo "- 📋 Results available in workflow artifacts" >> pr-summary.md
        else
          echo "- ⚠️ No test results found" >> pr-summary.md
        fi
        echo "" >> pr-summary.md
        
        # Add security info
        echo "### 🔒 Security Scanning" >> pr-summary.md
        echo "- 🔍 Vulnerability scanning (NuGet packages)" >> pr-summary.md
        echo "- 🛡️ CodeQL static analysis" >> pr-summary.md
        echo "- 🔐 Secret detection with TruffleHog" >> pr-summary.md
        echo "- � Filesystem security scanning with Trivy" >> pr-summary.md
        echo "- 📋 OWASP dependency check" >> pr-summary.md
        echo "- 🎯 SAST analysis with Semgrep" >> pr-summary.md
        echo "- 📊 Security reports available in artifacts" >> pr-summary.md
        echo "" >> pr-summary.md
        
        # Add downloadable artifacts information
        echo "### 📦 Available Artifacts" >> pr-summary.md
        echo "- 📊 Test results (TRX format)" >> pr-summary.md
        echo "- 📈 Code coverage reports (Cobertura XML)" >> pr-summary.md
        echo "- 🔒 Security scan results (SARIF format)" >> pr-summary.md
        echo "- 🛡️ Vulnerability reports (JSON/XML)" >> pr-summary.md
        echo "- 📋 Security audit logs" >> pr-summary.md
        echo "" >> pr-summary.md
        
        echo "---" >> pr-summary.md
        echo "*Generated by Setlist Studio CI/CD Pipeline* 🎵" >> pr-summary.md
    
    # Step 14: Add comprehensive test summary comment to pull request
    # Provides immediate feedback on build and test status in PR discussion
    - name: 💬 Add test summary to PR
      uses: marocchino/sticky-pull-request-comment@v2
      if: github.event_name == 'pull_request' # Only on pull requests
      with:
        recreate: true                   # Replace existing comment
        header: build-test-summary       # Unique identifier for build and test summary
        path: pr-summary.md              # Path to summary file
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    
    # Step 15: Add code coverage comment to pull request
    # Shows coverage metrics directly in PR for easy review
    - name: 💬 Add coverage comment to PR
      uses: marocchino/sticky-pull-request-comment@v2
      if: github.event_name == 'pull_request' && hashFiles('code-coverage-results.md') != '' # Only if coverage file exists
      with:
        recreate: false                  # Don't replace existing comments
        header: coverage-report           # Unique identifier to distinguish from security comments
        path: code-coverage-results.md   # Path to coverage results file
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # JOB 2: Docker Image Build and Container Testing
  # Builds containerized application and validates container functionality
  # Only runs after successful build and test completion
  build-docker:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: build-and-test              # Depends on successful build and tests
    if: success()                      # Only run if previous jobs succeeded
    
    steps:
    # Step 1: Checkout source code for Docker build
    - name: 🔄 Checkout code
      uses: actions/checkout@v4
    
    # Step 2: Setup Docker Buildx for advanced build features
    # Enables multi-platform builds and advanced caching
    - name: 🐳 Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    # Step 3: Install network utilities for container testing
    # Required for health checks and connectivity testing
    - name: 🔧 Install network tools
      run: |
        sudo apt-get update
        sudo apt-get install -y netcat-openbsd
    
    # Step 4: Build Docker image with optimized settings
    # Creates containerized version of the application
    - name: 🏗️ Build Docker image
      uses: docker/build-push-action@v5
      with:
        context: .                      # Build context (current directory)
        file: ./Dockerfile              # Dockerfile location
        push: false                     # Don't push to registry (build only)
        load: true                      # Load image into local Docker daemon for testing
        tags: setlist-studio:${{ github.sha }},setlist-studio:latest # Tag with commit SHA and latest
        cache-from: type=gha            # Use GitHub Actions cache for faster builds
        cache-to: type=gha,mode=max     # Store build cache for future runs
    
    # Step 5: Verify Docker image build and inspect configuration
    # Validates image creation and displays image information for debugging
    - name: 🔍 Verify Docker image
      run: |
        echo "Available Docker images:"
        docker images setlist-studio
        echo ""
        echo "Image details:"
        docker inspect setlist-studio:${{ github.sha }} --format='{{.Id}} {{.Created}} {{.Config.Env}} {{.Config.ExposedPorts}}'
        echo ""
        echo "Image layers:"
        docker history setlist-studio:${{ github.sha }} --no-trunc | head -10
    
    # Step 6: Test Docker container functionality and health
    # Validates that the containerized application starts and responds correctly
    - name: 🧪 Test Docker image
      run: |
        # Clean up any existing containers to avoid port conflicts
        docker stop test-container test-debug 2>/dev/null || true
        docker rm test-container test-debug 2>/dev/null || true
        
        echo "Testing container in foreground first (for debugging)..."
        timeout 10s docker run --rm --name test-debug -p 8081:8080 \
          -e ASPNETCORE_ENVIRONMENT=Development \
          -e ASPNETCORE_URLS=http://0.0.0.0:8080 \
          setlist-studio:${{ github.sha }} || echo "Container test completed or timed out"
        
        echo "Starting container in background..."
        docker run --rm -d --name test-container -p 8080:8080 \
          -e ASPNETCORE_ENVIRONMENT=Development \
          -e ASPNETCORE_URLS=http://0.0.0.0:8080 \
          setlist-studio:${{ github.sha }}
        
        echo "Waiting for container to start..."
        # Wait and check if container is running
        for i in {1..10}; do
          if docker ps --filter name=test-container --filter status=running --quiet | grep -q .; then
            echo "✅ Container is running after ${i}0 seconds"
            break
          else
            echo "⏳ Container not yet running, waiting... (${i}0s)"
            sleep 10
          fi
          
          if [ $i -eq 10 ]; then
            echo "❌ Container failed to start after 100 seconds"
            docker ps -a --filter name=test-container
            docker logs test-container
            exit 1
          fi
        done
        
        # Display container status for debugging
        echo "Container status:"
        docker ps -a --filter name=test-container
        
        echo "Initial container logs:"
        docker logs test-container
        
        # Test application health endpoint
        echo "Testing health endpoint..."
        # Get current container logs before testing
        echo "Current container logs:"
        docker logs test-container
        
        # Wait for application to fully initialize
        echo "Giving application more time to start..."
        sleep 10
        
        echo "Container logs after additional wait:"
        docker logs test-container
        
        # Try multiple connection attempts as the app might take time to start
        for i in {1..8}; do
          echo "Attempt $i: Testing application health"
          
          # Check if container is still running
          if ! docker ps --filter name=test-container --filter status=running --quiet | grep -q .; then
            echo "❌ Container is no longer running!"
            echo "Container status:"
            docker ps -a --filter name=test-container
            echo "Container exit code and details:"
            docker inspect test-container --format='{{.State.ExitCode}} {{.State.Error}}' || echo "Cannot inspect container"
            echo "Full container logs:"
            docker logs test-container
            echo "Container was likely terminated due to application startup failure"
            exit 1
          fi
          
          # Test application health using dedicated health endpoint (more reliable)
          health_response=$(curl -f -s -o /dev/null -w "%{http_code}" -m 10 http://localhost:8080/api/status 2>/dev/null || echo "000")
          
          if [ "$health_response" = "200" ] || [[ "$health_response" =~ ^2[0-9][0-9] ]]; then
            echo "✅ Application health check passed on attempt $i (HTTP $health_response)"
            echo "✅ API health endpoint is responding correctly"
            
            # Also test the root endpoint to ensure main app is working
            root_response=$(curl -s -o /dev/null -w "%{http_code}" -m 5 http://localhost:8080/ 2>/dev/null || echo "000")
            if [ "$root_response" = "200" ] || [[ "$root_response" =~ ^2[0-9][0-9] ]]; then
              echo "✅ Main application also responding (HTTP $root_response)"
            else
              echo "ℹ️ Main app has issues (HTTP $root_response) but health endpoint is working"
            fi
            break
          else
            echo "❌ Health check failed on attempt $i (HTTP $health_response)"
            
            # More detailed diagnostics
            echo "  📊 Container status:"
            docker exec test-container ps aux | head -10 || echo "    Cannot exec into container"
            
            echo "  🔍 Network connectivity:"
            docker exec test-container netstat -tuln | grep :5000 || echo "    Cannot check network status"
            
            echo "  📋 Latest logs:"
            docker logs --tail 20 test-container
            
            # Test basic connectivity
            echo "  🌐 Testing connectivity:"
            nc -z localhost 8080 && echo "    Port 8080 is open" || echo "    Port 8080 is closed"
            
            if [ $i -lt 8 ]; then
              echo "Retrying in 15 seconds..."
              sleep 15
            fi
          fi
          
          if [ $i -eq 8 ]; then
            echo "❌ Health check failed after $i attempts"
            echo ""
            echo "🔍 === FINAL DIAGNOSTICS ==="
            echo "Container status:"
            docker ps -a --filter name=test-container
            echo ""
            echo "Full container logs:"
            docker logs test-container
            echo ""
            echo "Container processes:"
            docker exec test-container ps aux || echo "Cannot exec into container"
            echo ""
            echo "Network information:"
            docker port test-container || echo "Cannot get port information"
            echo ""
            echo "Environment variables:"
            docker exec test-container env | grep -E "(ASPNET|DOTNET)" || echo "Cannot get environment"
            echo ""
            echo "Database directory:"
            docker exec test-container ls -la /app/data/ || echo "Cannot check database directory"
            echo ""
            echo "Application files:"
            docker exec test-container ls -la /app/ | head -10 || echo "Cannot list app files"
            echo ""
            echo "Testing connectivity:"
            curl -v -m 10 http://localhost:8080/api/status || echo "Cannot connect to health endpoint"
            echo ""
            echo "Testing main app:"
            curl -v -m 10 http://localhost:8080/ || echo "Cannot connect to base URL"
            echo ""
            docker stop test-container || true
            exit 1
          fi
        done
        
        echo "✅ Container test successful!"
        echo "Stopping container..."
        docker stop test-container

  deploy-preview:
    name: Deploy Preview
    runs-on: ubuntu-latest
    needs: [build-and-test, build-docker]
    if: github.event_name == 'pull_request' && success()
    environment: preview
    
    env:
      PR_NUMBER: ${{ github.event.number }}
      BRANCH: ${{ github.head_ref }}
    steps:
    - name: 🚀 Deploy to Preview Environment
      run: |
        echo "🎯 This would deploy to a preview environment"
        echo "PR Number: \"$PR_NUMBER\""
        echo "Branch: \"$BRANCH\""
        # Add your actual deployment commands here
    
    - name: 💬 Add deployment comment to PR
      uses: actions/github-script@v7
      with:
        script: |
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: '🚀 Preview deployment available at: https://preview-pr-${{ github.event.number }}.setlist-studio.dev'
          })